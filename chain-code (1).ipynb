{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import cv2\nimport numpy as np\nfrom sklearn import svm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom tensorflow.keras.datasets import mnist\n\n\n# Load the MNIST dataset\n(train_images, train_labels), _ = mnist.load_data()","metadata":{"execution":{"iopub.status.busy":"2024-05-24T12:02:46.179989Z","iopub.execute_input":"2024-05-24T12:02:46.180382Z","iopub.status.idle":"2024-05-24T12:03:01.918656Z","shell.execute_reply.started":"2024-05-24T12:02:46.180344Z","shell.execute_reply":"2024-05-24T12:03:01.917789Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-05-24 12:02:50.062451: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-24 12:02:50.062539: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-24 12:02:50.217690: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Example to explain the contours and chain code extracted from one image","metadata":{}},{"cell_type":"code","source":"image= train_images[0].reshape(28,28,1)\n\nret,thresh = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY )\ncontours,_= cv2.findContours(image=thresh, mode=cv2.RETR_TREE, method=cv2.CHAIN_APPROX_NONE)\n\ncontours = np.array(contours[0])\nboundary = contours.reshape(contours.shape[0],2)\n\nprint('coordinates =  ',boundary)\n\n\nchaincode=[]\nk=0\nwhile k<len(boundary)-1:\n    x,z=boundary[k]\n    l=k+1\n    next_x,next_z=boundary[l]\n    if(x==next_x and z+1==next_z):\n        code=0\n    elif(x-1==next_x and z+1==next_z):\n        code=1\n    elif(x-1==next_x and z==next_z):\n        code=2\n    elif(x-1==next_x and z-1==next_z):\n        code=3\n    elif(x==next_x and z-1==next_z):\n        code=4\n    elif(x+1==next_x and z-1==next_z):\n        code=5\n    elif(x+1==next_x and z==next_z):\n        code=6\n    elif(x+1==next_x and z+1==next_z):\n        code=7\n    k=k+1\n    chaincode.append(code)\n\nprint(\"chain =  \",chaincode)","metadata":{"execution":{"iopub.status.busy":"2024-05-24T12:03:01.920166Z","iopub.execute_input":"2024-05-24T12:03:01.920733Z","iopub.status.idle":"2024-05-24T12:03:01.958052Z","shell.execute_reply.started":"2024-05-24T12:03:01.920707Z","shell.execute_reply":"2024-05-24T12:03:01.957116Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"coordinates =   [[17  5]\n [16  6]\n [15  6]\n [14  6]\n [13  6]\n [12  6]\n [11  6]\n [10  7]\n [ 9  7]\n [ 8  7]\n [ 8  8]\n [ 9  9]\n [10  8]\n [11  9]\n [11 10]\n [11 11]\n [12 12]\n [13 13]\n [14 14]\n [15 15]\n [16 15]\n [17 16]\n [17 17]\n [16 18]\n [15 18]\n [14 19]\n [13 19]\n [12 20]\n [11 21]\n [10 21]\n [ 9 22]\n [ 8 22]\n [ 7 22]\n [ 6 23]\n [ 5 23]\n [ 4 24]\n [ 5 24]\n [ 6 24]\n [ 7 24]\n [ 8 24]\n [ 9 24]\n [10 24]\n [11 23]\n [12 23]\n [13 22]\n [14 21]\n [15 21]\n [16 20]\n [17 20]\n [18 19]\n [19 19]\n [19 18]\n [19 17]\n [19 16]\n [18 15]\n [17 15]\n [16 14]\n [15 13]\n [14 13]\n [13 12]\n [13 11]\n [12 10]\n [13  9]\n [14  8]\n [15  8]\n [16  8]\n [17  9]\n [17  8]\n [17  7]\n [18  6]\n [19  6]\n [20  6]\n [21  6]\n [22  6]\n [22  5]\n [21  5]\n [20  5]\n [19  6]\n [18  5]]\nchain =   [1, 2, 2, 2, 2, 2, 1, 2, 2, 0, 7, 5, 7, 0, 0, 7, 7, 7, 7, 6, 7, 0, 1, 2, 1, 2, 1, 1, 2, 1, 2, 2, 1, 2, 1, 6, 6, 6, 6, 6, 6, 5, 6, 5, 5, 6, 5, 6, 5, 6, 4, 4, 4, 3, 2, 3, 3, 2, 3, 4, 3, 5, 5, 6, 6, 7, 4, 4, 5, 6, 6, 6, 6, 4, 2, 2, 1, 3]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Feature extraction function using chain code\ndef extract_features(image):\n    # Convert image to binary\n    ret, thresh = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n\n    # Find contours\n    contours, _ = cv2.findContours(image=thresh, mode=cv2.RETR_TREE, method=cv2.CHAIN_APPROX_NONE)\n    contours = np.array(contours[0])\n    boundary = contours.reshape(contours.shape[0],2)\n\n\n    # Compute chain code\n    chaincode = []\n    k = 0\n    while k < len(boundary) - 1:\n        x, y = boundary[k]\n        l = k + 1\n        next_x, next_y = boundary[l]\n        if (x == next_x and y + 1 == next_y):\n            code = 0\n        elif (x - 1 == next_x and y + 1 == next_y):\n            code = 1\n        elif (x - 1 == next_x and y == next_y):\n            code = 2\n        elif (x - 1 == next_x and y - 1 == next_y):\n            code = 3\n        elif (x == next_x and y - 1 == next_y):\n            code = 4\n        elif (x + 1 == next_x and y - 1 == next_y):\n            code = 5\n        elif (x + 1 == next_x and y == next_y):\n            code = 6\n        elif (x + 1 == next_x and y + 1 == next_y):\n            code = 7\n        k = k + 1\n        chaincode.append(code)\n\n    return chaincode","metadata":{"execution":{"iopub.status.busy":"2024-05-24T12:03:01.959145Z","iopub.execute_input":"2024-05-24T12:03:01.959519Z","iopub.status.idle":"2024-05-24T12:03:01.970112Z","shell.execute_reply.started":"2024-05-24T12:03:01.959485Z","shell.execute_reply":"2024-05-24T12:03:01.969079Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Apply the chain code feature extraction on MNIST data set ","metadata":{}},{"cell_type":"code","source":"# Extract features from all images\nfeatures = [extract_features(image.reshape(28, 28, 1)) for image in train_images]\n\n# Find the maximum length of features\nmax_length = max(len(feature) for feature in features)\n\n# Pad or truncate features to the maximum length\npadded_features = [feature + [0] * (max_length - len(feature)) for feature in features]\n\n# Convert features to numpy array\nX = np.array(padded_features)\ny = train_labels  # Assuming train_labels contain the corresponding labels\n\n# Split data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-05-24T12:03:01.971930Z","iopub.execute_input":"2024-05-24T12:03:01.972281Z","iopub.status.idle":"2024-05-24T12:04:01.775598Z","shell.execute_reply.started":"2024-05-24T12:03:01.972248Z","shell.execute_reply":"2024-05-24T12:04:01.774774Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Using the extracted features on the SVM model","metadata":{}},{"cell_type":"code","source":"# Train SVM model\nclf = svm.SVC(kernel= \"poly\")\nclf.fit(X_train, y_train)\n\n# Predict\ny_pred = clf.predict(X_test)\n\n# Calculate accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy:\", accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-05-24T12:04:01.776661Z","iopub.execute_input":"2024-05-24T12:04:01.776927Z","iopub.status.idle":"2024-05-24T12:05:08.192160Z","shell.execute_reply.started":"2024-05-24T12:04:01.776905Z","shell.execute_reply":"2024-05-24T12:05:08.191130Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Accuracy: 0.901\n","output_type":"stream"}]}]}